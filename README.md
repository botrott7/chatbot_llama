# chatbot_llama 
## ChatBot на основе модели LLaMA с использованием FastAPI

## Описание проекта

Данный проект представляет собой простой чат-бот, разработанный с использованием модели LLaMA и фреймворка FastAPI. Бот обучен отвечать на вопросы пользователя, используя алгоритм генерации текста и предоставляя ответы на основе входных данных.

## Особенности проекта

- Взаимодействие с пользователем осуществляется через REST API с помощью фреймворка FastAPI.
- Вопросы пользователей передаются боту, который использует модель LLaMA для генерации ответов на основе входных данных.
- Проект поддерживает простой веб-интерфейс для общения с ботом.
- Логирование всех вопросов и ответов с уровнями отладки и ошибок осуществляется с использованием модуля logging.

## Требования к окружению

- Python 3.7+
- Установленные зависимости из файла requirements.txt
- Модель обучения [LLaMA model](https://huggingface.co/IlyaGusev/saiga_mistral_7b_gguf/blob/main/model-q8_0.gguf)

## Использование проекта

1. Установите все зависимости из файла requirements.txt с помощью команды pip install -r requirements.txt.
2. Убедитесь, что у вас находится модель LLaMA с именем model-q8_01.gguf в корневом каталоге проекта.
3. Запустите приложение с помощью команды python main.py.
4. Веб-интерфейс доступен по адресу http://localhost:8000.

## Доступные эндпоинты

- Эндпоинт / - главное меню приложения.
- Эндпоинт /messageAI (POST) - передает вопрос боту и получает ответ.
- Логирование в файл logfile.txt с уровнями отладки и ошибок.
